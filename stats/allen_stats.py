#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 18 13:47:59 2021

@author: heiko
"""

from allensdk.core.brain_observatory_cache import BrainObservatoryCache
import allensdk.brain_observatory.natural_scenes as ns
import allensdk.brain_observatory.stimulus_info as stim_info
import numpy as np
import pandas as pd
import os
import tqdm
import matplotlib.pyplot as plt
import pyrsa
from helpers import run_inference


def download(exp_id, folder='allen_data', boc=None):
    """ downloads a specific experiment and extracts the mean cell responses
    from the df/f traces for n frames after the exp_id"""
    if boc is None:
        boc = BrainObservatoryCache(manifest_file='boc/manifest.json')
    nwb_filename = 'boc/ophys_experiment_data/%d.nwb'
    if not os.path.isdir(folder):
        os.mkdir(folder)
    filename = os.path.join(folder, 'U_%d.npz' % exp_id)
    if not os.path.isfile(filename):
        exp_data = boc.get_ophys_experiment_data(exp_id)
        exp_ana = ns.NaturalScenes(exp_data)
        stim_table = exp_ana.stim_table
        stimulus = stim_table['frame']
        t_dff, dff = exp_data.get_dff_traces()
        U = np.empty((len(stim_table), exp_data.number_of_cells))
        for i in range(len(stim_table)):
            resp = dff[:, (stim_table['start'][i]+1):(stim_table['end'][i])]
            U[i] = np.mean(resp, 1)
        np.savez(filename, stimulus=stimulus, U=U)
        # remove file after U download to save space
        # os.remove(nwb_filename % exp_id)
    else:
        d_dict = np.load(filename)
        stimulus = d_dict['stimulus']
        U = d_dict['U']
    return U.shape


def download_all(folder='allen_data'):
    boc = BrainObservatoryCache(manifest_file='boc/manifest.json')
    csv_file = folder + '.csv'
    if not os.path.isfile(csv_file):
        experiments = boc.get_ophys_experiments(
            stimuli=[stim_info.NATURAL_SCENES],
            cre_lines=['Cux2-CreERT2', 'Emx1-IRES-Cre', 'Slc17a7-IRES2-Cre'])
        exp_df = pd.DataFrame(experiments)
        exp_df.to_csv(csv_file)
    else:
        exp_df = pd.read_csv(csv_file)
    order = np.random.permutation(len(exp_df))
    exp_df['n_stim'] = np.nan
    exp_df['n_cell'] = np.nan
    for idx in order:
        n_stim, n_cell = download(exp_df['id'][idx], folder=folder, boc=boc)
        print('downloaded %d: %d' % (idx, exp_df['id'][idx]))
        exp_df.at[idx, 'n_stim'] = n_stim
        exp_df.at[idx, 'n_cell'] = n_cell
    if not os.path.isfile(csv_file):
        exp_df.to_csv(csv_file)


def resample(n_subj, n_stim, n_repeat, n_cell, folder='allen_data',
             targeted_structure='VISal'):
    """ gets a resampled dataset generated by sampling from the allen dataset

    Args:
    n_subj (int): number of mice
    n_stim (int): number of stimuli
    n_repeat (int): number of repeats
    n_cell (int): number of cells
    folder (str, folder), optional:
        the folder with the downloaded data. The default is 'allen_data'.

    targeted structures are:
        'VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISrl'

    Returns
    -------
    list of pyrsa.data.Dataset for the requested data, one dataset per subject

    """
    csv_file = folder + '.csv'
    exp_df = pd.read_csv(csv_file)
    exp_df = exp_df[exp_df.n_cell >= n_cell]
    right_tar_df = exp_df[exp_df['targeted_structure'] == targeted_structure]
    subs = np.unique(right_tar_df['donor_name'])
    n_subj = min(n_subj, len(subs))
    subj_idx = subs[np.random.permutation(len(subs))[:n_subj]]
    stim_idx = np.random.permutation(118)[:n_stim]
    U_all = np.empty((n_subj, n_stim, n_repeat, n_cell))
    for i_subj, subj in enumerate(subj_idx):
        right_sub_df = right_tar_df[
            right_tar_df['donor_name'] == subj]
        if len(right_sub_df) == 1:
            exp_id = right_sub_df.iloc()[0]['id']
        else:
            k = np.random.randint(len(right_sub_df))
            exp_id = right_sub_df.iloc()[k]['id']
        dat = np.load('allen_data/U_%d.npz' % exp_id)
        U = dat['U']
        stimulus = dat['stimulus']
        for i_stim, stim in enumerate(stim_idx):
            U_stim = U[stimulus == stim]
            rep_idx = np.random.permutation(U_stim.shape[0])[:n_repeat]
            cell_idx = np.random.permutation(U_stim.shape[1])[:n_cell]
            U_all[i_subj, i_stim] = U_stim[rep_idx][:, cell_idx]
    U_pyrsa = U_all.transpose(0, 3, 1, 2).reshape(
        n_subj, n_cell, n_stim * n_repeat).transpose(0, 2, 1)
    stim = np.repeat(stim_idx, n_repeat)
    datasets = []
    for i_subj in range(n_subj):
        v = np.var(U_pyrsa[i_subj], 0)  # variance to exclude constant cells
        dataset = pyrsa.data.Dataset(
            U_pyrsa[i_subj][:, v > 0],
            obs_descriptors={
                'stim': stim},
            descriptors={
                'subj': i_subj,
                'n_repeat': n_repeat,
                'n_stim': n_stim,
                'n_cell': n_cell,
                'targeted_structure': targeted_structure}
            )
        datasets.append(dataset)
    return datasets


def get_all_data(folder='allen_data', targeted_structure='VISal', min_cell=20):
    csv_file = folder + '.csv'
    exp_df = pd.read_csv(csv_file)
    exp_df = exp_df[exp_df.n_cell >= min_cell]
    right_tar_df = exp_df[exp_df['targeted_structure'] == targeted_structure]
    subs = np.unique(right_tar_df['donor_name'])
    datasets = []
    for i_subj, subj in enumerate(subs):
        right_sub_df = right_tar_df[
            right_tar_df['donor_name'] == subj]
        for i_exp, exp_row in right_sub_df.iterrows():
            exp_id = exp_row['id']
            dat = np.load('allen_data/U_%d.npz' % exp_id)
            U = dat['U']
            stimulus = dat['stimulus']
            dataset = pyrsa.data.Dataset(
                U,
                obs_descriptors={
                    'stim': stimulus},
                descriptors={
                    'subj': i_subj,
                    'targeted_structure': targeted_structure}
                )
            datasets.append(dataset)
    return datasets


def get_model_rdm(folder='allen_data', method='crossnobis', sim_type='cosine',
                  targeted_structure='VISal', min_cell=20):
    file_name = os.path.join(folder, method, sim_type)
    os.makedirs(file_name, exist_ok=True)
    file_name = os.path.join(
        file_name, targeted_structure + '_' + str(min_cell) + '.hdf5')
    if os.path.exists(file_name):
        rdm = pyrsa.rdm.load_rdm(file_name)
    else:
        datasets = get_all_data(folder=folder, min_cell=min_cell,
                                targeted_structure=targeted_structure)
        # we don't have a cv_descriptor here
        rdms = pyrsa.rdm.calc_rdm(datasets, method=method, descriptor='stim',
                                  cv_descriptor=None)
        rdm = pyrsa.util.inference_util.pool_rdm(rdms, method=sim_type)
        rdm.save(file_name)
    return rdm


def get_models(folder='allen_data', method='crossnobis', sim_type='cosine',
               min_cell=20):
    target_structures = ['VISl', 'VISpm', 'VISrl', 'VISp', 'VISam', 'VISal']
    models = []
    for target in target_structures:
        rdm = get_model_rdm(
            folder=folder, method=method, sim_type=sim_type,
            targeted_structure=target, min_cell=min_cell)
        models.append(pyrsa.model.ModelFixed(target, rdm))
    return models


def sim_allen(
        idx, allen_folder='allen_data',
        n_cell=20, n_subj=10, n_stim=40, n_repeat=20,
        simulation_folder='sim_allen', n_sim=100,
        rdm_comparison='cosine', rdm_type='crossnobis',
        noise_type='eye', boot_type='both',
        start_idx=0, targeted_structure='VISp'):
    """ resamples the allen data and runs the RSA analysis on each sample
    always resamples subjects, cells, stimuli and repeats
    """
    fname_base = os.path.join(simulation_folder, '%05d' % idx)
    if not os.path.isdir(fname_base):
        os.makedirs(fname_base)
    res_name = os.path.join(fname_base, 'res_%03d.hdf5')
    models = get_models(folder=allen_folder, method=rdm_type,
                        sim_type=rdm_comparison, min_cell=n_cell)
    for i in tqdm.trange(start_idx, n_sim, position=1):
        data = resample(n_subj, n_stim, n_repeat, n_cell,
                        targeted_structure=targeted_structure)
        # calculate RDMs
        if noise_type == 'eye':
            noise = None
        else:
            noise = []
            for dataset in data:
                noise.append(pyrsa.data.noise.prec_from_measurements(
                    dataset, 'stim', method=noise_type))
        rdms = pyrsa.rdm.calc_rdm(data, method=rdm_type, descriptor='stim',
                                  cv_descriptor=None, noise=noise)
        # run analysis
        results = run_inference(models, rdms, method=rdm_comparison,
                                bootstrap=boot_type)
        results.save(res_name % (i))


def run_allen(file_add=None,
              allen_folder='allen_data', n_sim=100):
    tasks_file, simulation_folder, _ = _get_fnames(file_add)
    task_df = pd.read_csv(tasks_file, index_col=0)
    order = np.random.permutation(np.arange(len(task_df)))
    for i_task in tqdm.tqdm(order, position=0):
        row = task_df.iloc()[i_task]
        fname_base = os.path.join(simulation_folder, '%05d' % row.name)
        start_idx = 0
        while os.path.isfile(os.path.join(fname_base, 'res_%03d.hdf5' % start_idx)):
            start_idx += 1
        if start_idx < n_sim:
            sim_allen(
                row.name, allen_folder=allen_folder,
                n_cell=row.n_cell, n_subj=row.n_subj, n_stim=row.n_stim,
                n_repeat=row.n_repeat,
                simulation_folder=simulation_folder, n_sim=n_sim,
                rdm_comparison=row.rdm_comparison, rdm_type='crossnobis',
                noise_type=row.noise_type, boot_type=row.boot_type,
                start_idx=start_idx)
        task_df.at[i_task, 'finished'] = 1
        task_df.to_csv(tasks_file)


def save_task_list(file_add=None, targeted_structure=None):
    tasks_file, _, _ = _get_fnames(file_add)
    n_cell = [20, 40, 80]
    n_subj = [5, 10, 15]
    n_stim = [10, 20, 40]
    n_repeat = [10, 20, 40]
    noise_type = ['eye', 'diag', 'shrinkage_diag', 'shrinkage_eye']
    rdm_comparison = ['cosine', 'corr', 'corr_cov', 'cosine_cov']
    if targeted_structure is None:
        targeted_structure = ['VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISrl']
    boot_type = ['both', 'fancyboot']
    grid = np.meshgrid(boot_type, targeted_structure,
                       noise_type, rdm_comparison,
                       n_cell, n_subj, n_stim, n_repeat, [0])
    table = [i.flatten() for i in grid]
    df = pd.DataFrame(table).transpose()
    df.columns = ['boot_type', 'targeted_structure',
                  'noise_type', 'rdm_comparison',
                  'n_cell', 'n_subj', 'n_stim', 'n_repeat',
                  'finished']
    df.to_csv(tasks_file)


def summarize_allen(file_add):
    tasks_file, simulation_folder, summary_file = _get_fnames(file_add)
    task_df = pd.read_csv(tasks_file, index_col=0)
    means = []
    variances = []
    for i, row in tqdm.tqdm(task_df.iterrows()):
        fname_base = os.path.join(simulation_folder, str(row.name))
        mean = np.nan * np.zeros((100, 6))
        variance = np.nan * np.zeros((100, 6, 6))
        if os.path.exists(fname_base):
            for file in os.listdir(fname_base):
                idx = int(file.split('_')[1].split('.')[0])  # res_XXX.hdf5
                try:
                    res = pyrsa.inference.load_results(os.path.join(fname_base, file),
                                                       file_type='hdf5')
                    if res.evaluations.ndim == 2:
                        no_nan_idx = ~np.isnan(res.evaluations[:, 0])
                    elif res.evaluations.ndim == 3:
                        no_nan_idx = \
                            ~np.isnan(res.evaluations[:, 0, 0])
                    if np.any(no_nan_idx):
                        m = np.mean(res.evaluations[no_nan_idx],
                                    axis=0)
                        while m.ndim > 1:
                            m = np.mean(m, axis=-1)
                        mean[idx] = m
                        variance[idx] = res.variances
                    else:
                        raise OSError('no valid results')
                except OSError:
                    mean[idx] = np.nan
                    variance[idx] = np.nan
        means.append(mean)
        variances.append(variance)
    means = np.array(means)
    variances = np.array(variances)
    np.savez(summary_file, means=means, variances=variances)


def overall_ana(allen_folder='allen_data', rdm_comparison='cosine',
                rdm_type='crossnobis', min_cell=1,
                noise_type='eye', boot_type='both'):
    models = get_models(folder='allen_data', method=rdm_type,
                        sim_type=rdm_comparison, min_cell=1)
    models = [models[i] for i in (3, 0, 5, 2, 4, 1)]
    target_structures = ['VISp', 'VISl', 'VISal', 'VISrl', 'VISam', 'VISpm']
    data_rdms = {}
    results = []
    for target in target_structures:
        datasets = get_all_data(
            folder=allen_folder, targeted_structure=target, min_cell=min_cell)
        rdms = pyrsa.rdm.calc_rdm(datasets, method=rdm_type, descriptor='stim',
                                  cv_descriptor=None)
        data_rdms[target] = rdms
        results.append(pyrsa.inference.eval_fixed(models, rdms, method=rdm_comparison))
        pyrsa.vis.plot_model_comparison(results[-1])
    pair_sim = np.zeros((len(target_structures), len(target_structures)))
    for i_target in range(len(target_structures)):
        pair_sim[i_target] = np.mean(results[i_target].evaluations, -1)
    plt.figure()
    plt.imshow(pair_sim, cmap='bone')
    cb = plt.colorbar()
    if rdm_comparison == 'cosine':
        cb.set_label('rdm cosine similarity', fontsize=14)
    elif rdm_comparison == 'corr':
        cb.set_label('rdm correlation', fontsize=14)
    elif rdm_comparison == 'cosine_cov':
        cb.set_label('whitened cosine similarity', fontsize=14)
    elif rdm_comparison == 'corr_cov':
        cb.set_label('whitened rdm correlation', fontsize=14)
    plt.xticks(np.arange(len(target_structures)),
               ['V1', 'L', 'AL', 'RL', 'AM', 'PM'],
               fontsize=18)
    plt.yticks(np.arange(len(target_structures)),
               ['V1', 'L', 'AL', 'RL', 'AM', 'PM'],
               fontsize=18)
    plt.xlabel('model RDM', fontsize=16)
    plt.ylabel('data RDM', fontsize=16)
    plt.savefig('figures/allen_%s_%s.pdf' % (rdm_type, rdm_comparison),
                bbox_inches='tight')


def _get_fnames(file_add):
    if file_add is None:
        tasks_file = 'allen_tasks.csv'
        simulation_folder = 'sim_allen'
        summary_file = 'allen_results.npz'
    else:
        tasks_file = 'allen_tasks_' + file_add + '.csv'
        simulation_folder = 'sim_allen_' + file_add
        summary_file = 'allen_results' + file_add + '.npz'
    return tasks_file, simulation_folder, summary_file


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('-f', '--folder', type=str,
                        help='where should the allen data be?',
                        default='allen_data')
    parser.add_argument('-a', '--file_add', type=str,
                        help='additional tag to file_names',
                        default=None)
    parser.add_argument('-t', '--targeted_structure', nargs='+',
                        help='which target should be parsed',
                        default=None)
    parser.add_argument('action', help='what to do?', type=str,
                        choices=['download', 'save_list', 'run', 'nothing', 'summarize'],
                        default='nothing', nargs='?')
    args = parser.parse_args()
    if args.action == 'download':
        download_all(args.folder)
    elif args.action == 'save_list':
        save_task_list(file_add=args.file_add,
                       targeted_structure=args.targeted_structure)
    elif args.action == 'run':
        run_allen(
            file_add=args.file_add,
            allen_folder=args.folder)
    elif args.action == 'summarize':
        summarize_allen(file_add=args.file_add)
    else:
        print('No action selected, I am done!')
