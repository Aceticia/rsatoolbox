#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 18 13:47:59 2021

@author: heiko
"""

import sys, traceback
from allensdk.core.brain_observatory_cache import BrainObservatoryCache
import allensdk.brain_observatory.natural_scenes as ns
import allensdk.brain_observatory.stimulus_info as stim_info
import numpy as np
import pandas as pd
import os
import tqdm
import matplotlib.pyplot as plt
import rsatoolbox
from helpers import run_inference


def download(exp_id, folder='allen_data', boc=None):
    """ downloads a specific experiment and extracts the mean cell responses
    from the df/f traces for n frames after the exp_id"""
    if boc is None:
        boc = BrainObservatoryCache(manifest_file='boc/manifest.json')
    # nwb_filename = 'boc/ophys_experiment_data/%d.nwb'
    if not os.path.isdir(folder):
        os.mkdir(folder)
    filename = os.path.join(folder, 'U_%d.npz' % exp_id)
    if not os.path.isfile(filename):
        exp_data = boc.get_ophys_experiment_data(exp_id)
        exp_ana = ns.NaturalScenes(exp_data)
        stim_table = exp_ana.stim_table
        stimulus = stim_table['frame']
        t_dff, dff = exp_data.get_dff_traces()
        U = np.empty((len(stim_table), exp_data.number_of_cells))
        for i in range(len(stim_table)):
            resp = dff[:, (stim_table['start'][i]+1):(stim_table['end'][i])]
            U[i] = np.mean(resp, 1)
        np.savez(filename, stimulus=stimulus, U=U)
        # remove file after U download to save space
        # os.remove(nwb_filename % exp_id)
    else:
        d_dict = np.load(filename)
        stimulus = d_dict['stimulus']
        U = d_dict['U']
    return U.shape


def download_all(folder='allen_data'):
    boc = BrainObservatoryCache(manifest_file='boc/manifest.json')
    csv_file = folder + '.csv'
    if not os.path.isfile(csv_file):
        experiments = boc.get_ophys_experiments(
            stimuli=[stim_info.NATURAL_SCENES],
            cre_lines=['Cux2-CreERT2', 'Emx1-IRES-Cre', 'Slc17a7-IRES2-Cre'])
        exp_df = pd.DataFrame(experiments)
        exp_df.to_csv(csv_file)
    else:
        exp_df = pd.read_csv(csv_file)
    order = np.random.permutation(len(exp_df))
    exp_df['n_stim'] = np.nan
    exp_df['n_cell'] = np.nan
    for idx in order:
        n_stim, n_cell = download(exp_df['id'][idx], folder=folder, boc=boc)
        print('downloaded %d: %d' % (idx, exp_df['id'][idx]))
        exp_df.at[idx, 'n_stim'] = n_stim
        exp_df.at[idx, 'n_cell'] = n_cell
    if not os.path.isfile(csv_file):
        exp_df.to_csv(csv_file)


def resample(n_subj, n_stim, n_repeat, n_cell, folder='allen_data',
             targeted_structure='VISal', replacement=True):
    """ gets a resampled dataset generated by sampling from the allen dataset

    Args:
    n_subj (int): number of mice
    n_stim (int): number of stimuli
    n_repeat (int): number of repeats
    n_cell (int): number of cells
    folder (str, folder), optional:
        the folder with the downloaded data. The default is 'allen_data'.

    targeted structures are:
        'VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISrl'

    Returns
    -------
    list of rsatoolbox.data.Dataset for the requested data, one dataset per subject

    """
    csv_file = folder + '.csv'
    exp_df = pd.read_csv(csv_file)
    exp_df = exp_df[exp_df.n_cell >= n_cell]
    right_tar_df = exp_df[exp_df['targeted_structure'] == targeted_structure]
    subs = np.unique(right_tar_df['donor_name'])
    n_subj = min(n_subj, len(subs))
    if replacement:
        subj_idx = subs[np.random.randint(len(subs), size=n_subj)]
        stim_idx = np.random.randint(118, size=n_stim)
    else:
        subj_idx = subs[np.random.permutation(len(subs))[:n_subj]]
        stim_idx = np.random.permutation(118)[:n_stim]
    stim_idx.sort()
    U_all = np.empty((n_subj, n_stim, n_repeat, n_cell))
    for i_subj, subj in enumerate(subj_idx):
        right_sub_df = right_tar_df[
            right_tar_df['donor_name'] == subj]
        if len(right_sub_df) == 1:
            exp_id = right_sub_df.iloc()[0]['id']
        else:
            k = np.random.randint(len(right_sub_df))
            exp_id = right_sub_df.iloc()[k]['id']
        dat = np.load('allen_data/U_%d.npz' % exp_id)
        U = dat['U']
        stimulus = dat['stimulus']
        if replacement:
            cell_idx = np.random.randint(U.shape[1], size=n_cell)
        else:
            cell_idx = np.random.permutation(U.shape[1])[:n_cell]
        for i_stim, stim in enumerate(stim_idx):
            U_stim = U[stimulus == stim]
            if replacement:
                rep_idx = np.random.randint(U_stim.shape[0], size=n_repeat)
            else:
                rep_idx = np.random.permutation(U_stim.shape[0])[:n_repeat]
            U_all[i_subj, i_stim] = U_stim[rep_idx][:, cell_idx]
    U_rsatoolbox = U_all.transpose(0, 3, 1, 2).reshape(
        n_subj, n_cell, n_stim * n_repeat).transpose(0, 2, 1)
    stim = np.repeat(stim_idx, n_repeat)
    i_stim = np.repeat(np.arange(len(stim_idx)), n_repeat)
    datasets = []
    for i_subj in range(n_subj):
        v = np.var(U_rsatoolbox[i_subj], 0)  # variance to exclude constant cells
        dataset = rsatoolbox.data.Dataset(
            U_rsatoolbox[i_subj][:, v > 0],
            obs_descriptors={
                'stim': stim,
                'i_stim': i_stim},
            descriptors={
                'subj': i_subj,
                'n_repeat': n_repeat,
                'n_stim': n_stim,
                'n_cell': n_cell,
                'targeted_structure': targeted_structure}
            )
        datasets.append(dataset)
    return datasets, stim_idx


def get_all_data(folder='allen_data', targeted_structure='VISal', min_cell=20):
    csv_file = folder + '.csv'
    exp_df = pd.read_csv(csv_file)
    exp_df = exp_df[exp_df.n_cell >= min_cell]
    right_tar_df = exp_df[exp_df['targeted_structure'] == targeted_structure]
    subs = np.unique(right_tar_df['donor_name'])
    datasets = []
    for i_subj, subj in enumerate(subs):
        right_sub_df = right_tar_df[
            right_tar_df['donor_name'] == subj]
        for i_exp, exp_row in right_sub_df.iterrows():
            exp_id = exp_row['id']
            dat = np.load('allen_data/U_%d.npz' % exp_id)
            U = dat['U']
            stimulus = dat['stimulus']
            dataset = rsatoolbox.data.Dataset(
                U,
                obs_descriptors={
                    'stim': stimulus},
                descriptors={
                    'subj': i_subj,
                    'targeted_structure': targeted_structure}
                )
            datasets.append(dataset)
    return datasets


def get_model_rdm(folder='allen_data', method='crossnobis', sim_type='cosine',
                  targeted_structure='VISal', min_cell=20):
    file_name = os.path.join(folder, method, sim_type)
    os.makedirs(file_name, exist_ok=True)
    file_name = os.path.join(
        file_name, targeted_structure + '_' + str(min_cell) + '.hdf5')
    if os.path.exists(file_name):
        rdm = rsatoolbox.rdm.load_rdm(file_name)
    else:
        datasets = get_all_data(folder=folder, min_cell=min_cell,
                                targeted_structure=targeted_structure)
        # we don't have a cv_descriptor here
        rdms = rsatoolbox.rdm.calc_rdm(datasets, method=method, descriptor='stim',
                                       cv_descriptor=None)
        rdm = rsatoolbox.util.inference_util.pool_rdm(rdms, method=sim_type)
        rdm.save(file_name)
    return rdm


def get_models(folder='allen_data', method='crossnobis', sim_type='cosine',
               min_cell=20, stim_idx=np.arange(-1, 117)):
    target_structures = ['VISl', 'VISpm', 'VISrl', 'VISp', 'VISam', 'VISal']
    models = []
    for target in target_structures:
        rdm = get_model_rdm(
            folder=folder, method=method, sim_type=sim_type,
            targeted_structure=target, min_cell=min_cell)
        rdm = rdm.subsample_pattern('stim', stim_idx)
        rdm.dissimilarities[np.isnan(rdm.dissimilarities)] = 0
        models.append(rsatoolbox.model.ModelFixed(target, rdm))
    return models


def sim_allen(
        idx, allen_folder='allen_data',
        n_cell=20, n_subj=10, n_stim=40, n_repeat=20,
        simulation_folder='sim_allen', n_sim=100,
        rdm_comparison='cosine', rdm_type='crossnobis',
        noise_type='eye', boot_type='both',
        start_idx=0, targeted_structure='VISp'):
    """ resamples the allen data and runs the RSA analysis on each sample
    always resamples subjects, cells, stimuli and repeats
    """
    fname_base = os.path.join(simulation_folder, '%05d' % idx)
    if not os.path.isdir(fname_base):
        os.makedirs(fname_base)
    res_name = os.path.join(fname_base, 'res_%03d.hdf5')
    for i in tqdm.trange(start_idx, n_sim, position=1):
        data, stim_idx = resample(n_subj, n_stim, n_repeat, n_cell,
                                  targeted_structure=targeted_structure)
        models = get_models(folder=allen_folder, method=rdm_type,
                            sim_type=rdm_comparison, min_cell=n_cell,
                            stim_idx=stim_idx)
        # calculate RDMs
        if noise_type == 'eye':
            noise = None
        else:
            noise = []
            for dataset in data:
                noise.append(rsatoolbox.data.noise.prec_from_measurements(
                    dataset, 'i_stim', method=noise_type))
        rdms = rsatoolbox.rdm.calc_rdm(data, method=rdm_type, descriptor='i_stim',
                                       cv_descriptor=None, noise=noise)
        # run analysis
        results = run_inference(models, rdms, method=rdm_comparison,
                                bootstrap=boot_type)
        results.save(res_name % (i))


def run_allen(file_add=None,
              allen_folder='allen_data', n_sim=100):
    tasks_file, simulation_folder, _ = _get_fnames(file_add)
    task_df = pd.read_csv(tasks_file, index_col=0)
    order = np.random.permutation(np.arange(len(task_df)))
    for i_task in tqdm.tqdm(order, position=0):
        row = task_df.iloc()[i_task]
        fname_base = os.path.join(simulation_folder, '%05d' % row.name)
        print(row, flush=True)
        start_idx = 0
        while os.path.isfile(os.path.join(fname_base, 'res_%03d.hdf5' % start_idx)):
            start_idx += 1
        try:
            if start_idx < n_sim:
                sim_allen(
                    row.name, allen_folder=allen_folder,
                    n_cell=row.n_cell, n_subj=row.n_subj, n_stim=row.n_stim,
                    n_repeat=row.n_repeat,
                    simulation_folder=simulation_folder, n_sim=n_sim,
                    rdm_comparison=row.rdm_comparison, rdm_type='crossnobis',
                    noise_type=row.noise_type, boot_type=row.boot_type,
                    start_idx=start_idx,
                    targeted_structure=row.targeted_structure)
            # task_df.at[i_task, 'finished'] = 1
            # task_df.to_csv(tasks_file)
        except Exception as err:
            exc_type, exc_value, exc_traceback = sys.exc_info()
            traceback.print_exception(exc_type, exc_value, exc_traceback)
            # print(err, flush=True)


def save_task_list(file_add=None, targeted_structure=None):
    tasks_file, _, _ = _get_fnames(file_add)
    n_cell = [20, 40, 80]
    n_subj = [5, 10, 15]
    n_stim = [10, 20, 40]
    n_repeat = [10, 20, 40]
    noise_type = ['eye', 'diag', 'shrinkage_diag', 'shrinkage_eye']
    rdm_comparison = ['cosine', 'corr', 'corr_cov', 'cosine_cov']
    if targeted_structure is None:
        targeted_structure = ['VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISrl']
    boot_type = ['both', 'fancyboot']
    grid = np.meshgrid(boot_type, targeted_structure,
                       noise_type, rdm_comparison,
                       n_cell, n_subj, n_stim, n_repeat, [0])
    table = [i.flatten() for i in grid]
    df = pd.DataFrame(table).transpose()
    df.columns = ['boot_type', 'targeted_structure',
                  'noise_type', 'rdm_comparison',
                  'n_cell', 'n_subj', 'n_stim', 'n_repeat',
                  'finished']
    df.to_csv(tasks_file)


def summarize_allen(file_add):
    tasks_file, simulation_folder, summary_file = _get_fnames(file_add)
    task_df = pd.read_csv(tasks_file, index_col=0)
    means = []
    variances = []
    for i, row in tqdm.tqdm(task_df.iterrows()):
        fname_base = os.path.join(simulation_folder, '%05d' % row.name)
        mean = np.nan * np.zeros((100, 6))
        variance = np.nan * np.zeros((100, 6))
        if os.path.exists(fname_base):
            for file in os.listdir(fname_base):
                idx = int(file.split('_')[1].split('.')[0])  # res_XXX.hdf5
                try:
                    res = rsatoolbox.inference.load_results(os.path.join(fname_base, file),
                                                            file_type='hdf5')
                    if res.evaluations.ndim == 2:
                        no_nan_idx = ~np.isnan(res.evaluations[:, 0])
                    elif res.evaluations.ndim == 3:
                        no_nan_idx = \
                            ~np.isnan(res.evaluations[:, 0, 0])
                    if np.any(no_nan_idx):
                        m = np.mean(res.evaluations[no_nan_idx],
                                    axis=0)
                        while m.ndim > 1:
                            m = np.mean(m, axis=-1)
                        mean[idx] = m
                        if res.variances.shape[-1] == 6:
                            variance[idx] = rsatoolbox.util.inference_util.extract_variances(
                                res.variances, nc_included=False)[0]
                        else:
                            variance[idx] = rsatoolbox.util.inference_util.extract_variances(
                                res.variances, nc_included=True)[0]
                    else:
                        raise OSError('no valid results')
                except OSError:
                    mean[idx] = np.nan
                    variance[idx] = np.nan
        means.append(mean)
        variances.append(variance)
    means = np.array(means)
    variances = np.array(variances)
    np.savez(summary_file, means=means, variances=variances)


def overall_ana(allen_folder='allen_data', rdm_comparison='cosine',
                rdm_type='crossnobis', min_cell=1,
                noise_type='eye', boot_type='both'):
    target_structures = ['VISp', 'VISl', 'VISal', 'VISrl', 'VISam', 'VISpm']
    data_rdms = {}
    mean_rdm = {}
    for target in target_structures:
        datasets = get_all_data(
            folder=allen_folder, targeted_structure=target, min_cell=min_cell)
        rdms = rsatoolbox.rdm.calc_rdm(datasets, method=rdm_type, descriptor='stim',
                                       cv_descriptor=None)
        data_rdms[target] = rdms
        mean_rdm[target] = rsatoolbox.util.pooling.pool_rdm(
            rdms, method=rdm_comparison)
    pair_sim = np.zeros((len(target_structures), len(target_structures)))
    for i_t, i_target in enumerate(target_structures):
        for j_t, j_target in enumerate(target_structures):
            if i_target == j_target:
                evals = []
                rdms = data_rdms[i_target]
                for i_rdm in range(data_rdms[i_target].n_rdm):
                    test = rdms.subset('index', i_rdm)
                    train = rdms.subset('index', np.setdiff1d(
                        np.arange(data_rdms[i_target].n_rdm), i_rdm))
                    m_rdm = rsatoolbox.util.pooling.pool_rdm(
                        train, method=rdm_comparison)
                    evals.append(rsatoolbox.rdm.compare(
                        test, m_rdm))
            else:
                evals = rsatoolbox.rdm.compare(
                    data_rdms[i_target], mean_rdm[j_target], method=rdm_comparison)
            pair_sim[i_t, j_t] = np.mean(evals)
    plt.figure()
    plt.imshow(pair_sim, cmap='bone')
    cb = plt.colorbar()
    if rdm_comparison == 'cosine':
        cb.set_label('rdm cosine similarity', fontsize=14)
    elif rdm_comparison == 'corr':
        cb.set_label('rdm correlation', fontsize=14)
    elif rdm_comparison == 'cosine_cov':
        cb.set_label('whitened cosine similarity', fontsize=14)
    elif rdm_comparison == 'corr_cov':
        cb.set_label('whitened rdm correlation', fontsize=14)
    plt.xticks(np.arange(len(target_structures)),
               ['V1', 'L', 'AL', 'RL', 'AM', 'PM'],
               fontsize=18)
    plt.yticks(np.arange(len(target_structures)),
               ['V1', 'L', 'AL', 'RL', 'AM', 'PM'],
               fontsize=18)
    plt.xlabel('model RDM', fontsize=16)
    plt.ylabel('data RDM', fontsize=16)
    plt.savefig('figures/allen_%s_%s.pdf' % (rdm_type, rdm_comparison),
                bbox_inches='tight')


def sim_cells(subj=225036, n_sim=100, folder='allen_data',
              targeted_structure='VISp', replacement=True,
              n_cell=40, start_idx=0, n_stim=20, n_repeat=20,
              rdm_type='crossnobis', rdm_comparison='cosine',
              boot_type='fancyboot', save_file='sim_cell/res_%03d.hdf5'):
    """ subsampling cells
    """
    os.makedirs(os.path.dirname(save_file), exist_ok=True)
    csv_file = folder + '.csv'
    exp_df = pd.read_csv(csv_file)
    exp_df = exp_df[exp_df.n_cell >= n_cell]
    right_tar_df = exp_df[exp_df['targeted_structure'] == targeted_structure]
    # get models
    models = get_models(min_cell=1, method=rdm_type, sim_type=rdm_comparison)
    # get data for chosen subject
    
    for i in tqdm.trange(start_idx, n_sim, position=1):
        # subset cells, stimuli and repeats
        # generate RDMs
        # run inference
        # save results
        if replacement:
            stim_idx = np.random.randint(118, size=n_stim)
        else:
            stim_idx = np.random.permutation(118)[:n_stim]
        stim_idx.sort()
        U_all = np.empty((n_stim, n_repeat, n_cell))
        right_sub_df = right_tar_df[
            right_tar_df['donor_name'] == subj]
        if len(right_sub_df) == 1:
            exp_id = right_sub_df.iloc()[0]['id']
        else:
            k = np.random.randint(len(right_sub_df))
            exp_id = right_sub_df.iloc()[k]['id']
        dat = np.load('allen_data/U_%d.npz' % exp_id)
        U = dat['U']
        stimulus = dat['stimulus']
        if replacement:
            cell_idx = np.random.randint(U.shape[1], size=n_cell)
        else:
            cell_idx = np.random.permutation(U.shape[1])[:n_cell]
        for i_stim, stim in enumerate(stim_idx):
            U_stim = U[stimulus == stim]
            if replacement:
                rep_idx = np.random.randint(U_stim.shape[0], size=n_repeat)
            else:
                rep_idx = np.random.permutation(U_stim.shape[0])[:n_repeat]
            U_all[i_stim] = U_stim[rep_idx][:, cell_idx]
        U_rsatoolbox = U_all.transpose(2, 0, 1).reshape(
            n_cell, n_stim * n_repeat).transpose(1, 0)
        stim = np.repeat(stim_idx, n_repeat)
        i_stim = np.repeat(np.arange(len(stim_idx)), n_repeat)
        datasets = []
        v = np.var(U_rsatoolbox, 0)  # variance to exclude constant cells
        for i_cell in range(n_cell):
            if v[i_cell] > 0:
                dataset = rsatoolbox.data.Dataset(
                    U_rsatoolbox[:, i_cell].reshape(-1, 1),
                    obs_descriptors={
                        'stim': stim,
                        'i_stim': i_stim},
                    descriptors={
                        'subj': subj,
                        'n_repeat': n_repeat,
                        'n_stim': n_stim,
                        'n_cell': n_cell,
                        'targeted_structure': targeted_structure}
                    )
                datasets.append(dataset)
        rdms = rsatoolbox.rdm.calc_rdm(
            datasets, method=rdm_type, descriptor='i_stim',
            cv_descriptor=None)
        results = run_inference(models, rdms, method=rdm_comparison,
                                bootstrap=boot_type)
        results.save(save_file % i)


def run_cells():
    df = _get_cells_list()
    order = np.random.permutation(np.arange(len(df)))
    for idx in tqdm.tqdm(order, position=0):
        start_idx = 0
        save_file = f'sim_cell/{idx}/res_%03d.hdf5'
        while os.path.isfile(os.path.join(save_file % start_idx)):
            start_idx += 1
        sim_cells(
            targeted_structure=df['targeted_structure'][idx],
            n_cell=df['n_cell'][idx], n_stim=df['n_stim'][idx],
            n_repeat=df['n_repeat'][idx], start_idx=start_idx,
            rdm_type=df['rdm_type'][idx], rdm_comparison=df['rdm_comparison'][idx],
            boot_type='fancyboot', save_file=save_file)


def summarize_cells():
    tasks_file, simulation_folder, summary_file = _get_fnames()
    simulation_folder = 'sim_cell'
    summary_file = 'cell_results.npz'
    task_df = _get_cells_list()
    means = []
    variances = []
    for i, row in tqdm.tqdm(task_df.iterrows()):
        fname_base = os.path.join(simulation_folder, '%d' % row.name)
        mean = np.nan * np.zeros((100, 6))
        variance = np.nan * np.zeros((100, 6))
        if os.path.exists(fname_base):
            for file in os.listdir(fname_base):
                idx = int(file.split('_')[1].split('.')[0])  # res_XXX.hdf5
                try:
                    res = rsatoolbox.inference.load_results(os.path.join(fname_base, file),
                                                            file_type='hdf5')
                    if res.evaluations.ndim == 2:
                        no_nan_idx = ~np.isnan(res.evaluations[:, 0])
                    elif res.evaluations.ndim == 3:
                        no_nan_idx = \
                            ~np.isnan(res.evaluations[:, 0, 0])
                    elif res.evaluations.ndim == 4:
                        no_nan_idx = \
                            np.all(np.isfinite(res.evaluations[:, 0, 0]), -1)
                    if np.any(no_nan_idx):
                        m = np.mean(res.evaluations[no_nan_idx],
                                    axis=0)
                        while m.ndim > 1:
                            m = np.mean(m, axis=-1)
                        mean[idx] = m
                        if res.variances.shape[-1] == 6:
                            variance[idx] = rsatoolbox.util.inference_util.extract_variances(
                                res.variances, nc_included=False)[0]
                        else:
                            variance[idx] = rsatoolbox.util.inference_util.extract_variances(
                                res.variances, nc_included=True)[0]
                    else:
                        raise OSError('no valid results')
                except OSError:
                    mean[idx] = np.nan
                    variance[idx] = np.nan
        means.append(mean)
        variances.append(variance)
    means = np.array(means)
    variances = np.array(variances)
    np.savez(summary_file, means=means, variances=variances)


def _get_cells_list():
    n_cell = [10, 20, 40]
    n_stim = [10, 20, 40]
    n_repeat = [5, 10, 20]
    rdm_type = 'crossnobis'
    comparison = ['cosine', 'corr', 'cosine_cov', 'corr_cov']
    targeted_structure = ['VISp']
    boot_type = ['fancyboot']
    grid = np.meshgrid(
        boot_type, targeted_structure, rdm_type,
        comparison,
        n_cell, n_stim, n_repeat)
    table = [i.flatten() for i in grid]
    df = pd.DataFrame(table).transpose()
    df.columns = ['boot_type', 'targeted_structure', 'rdm_type',
                  'rdm_comparison',
                  'n_cell', 'n_stim', 'n_repeat']
    return df
    

def _get_fnames(file_add=None):
    if file_add is None:
        tasks_file = 'allen_tasks.csv'
        simulation_folder = 'sim_allen'
        summary_file = 'allen_results.npz'
    else:
        tasks_file = 'allen_tasks_' + file_add + '.csv'
        simulation_folder = 'sim_allen_' + file_add
        summary_file = 'allen_results' + file_add + '.npz'
    return tasks_file, simulation_folder, summary_file


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('-f', '--folder', type=str,
                        help='where should the allen data be?',
                        default='allen_data')
    parser.add_argument('-a', '--file_add', type=str,
                        help='additional tag to file_names',
                        default=None)
    parser.add_argument('-t', '--targeted_structure', nargs='+',
                        help='which target should be parsed',
                        default=None)
    parser.add_argument('action', help='what to do?', type=str,
                        choices=['download', 'save_list', 'run', 'nothing', 'summarize',
                                 'cells'],
                        default='nothing', nargs='?')
    args = parser.parse_args()
    if args.action == 'download':
        download_all(args.folder)
    elif args.action == 'save_list':
        save_task_list(file_add=args.file_add,
                       targeted_structure=args.targeted_structure)
    elif args.action == 'run':
        run_allen(
            file_add=args.file_add,
            allen_folder=args.folder)
    elif args.action == 'summarize':
        summarize_allen(file_add=args.file_add)
    elif args.action == 'cells':
        run_cells()
    else:
        print('No action selected, I am done!')
