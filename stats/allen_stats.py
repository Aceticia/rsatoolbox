#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 18 13:47:59 2021

@author: heiko
"""

from allensdk.core.brain_observatory_cache import BrainObservatoryCache
import allensdk.brain_observatory.natural_scenes as ns
import allensdk.brain_observatory.stimulus_info as stim_info
import numpy as np
import json
import pandas as pd
import os
import tqdm
import pyrsa
from helpers import run_inference


boc = BrainObservatoryCache(manifest_file='boc/manifest.json')
nwb_filename = 'boc/ophys_experiment_data/%d.nwb'


def download(exp_id, folder='allen_data'):
    """ downloads a specific experiment and extracts the mean cell responses
    from the df/f traces for n frames after the exp_id"""
    if not os.path.isdir(folder):
        os.mkdir(folder)
    filename = os.path.join(folder, 'U_%d.npz' % exp_id)
    if not os.path.isfile(filename):
        exp_data = boc.get_ophys_experiment_data(exp_id)
        exp_ana = ns.NaturalScenes(exp_data)
        stim_table = exp_ana.stim_table
        stimulus = stim_table['frame']
        t_dff, dff = exp_data.get_dff_traces()
        U = np.empty((len(stim_table), exp_data.number_of_cells))
        for i in range(len(stim_table)):
            resp = dff[:, (stim_table['start'][i]+1):(stim_table['end'][i])]
            U[i] = np.mean(resp, 1)
        np.savez(filename, stimulus=stimulus, U=U)
        # remove file after U download to save space
        # os.remove(nwb_filename % exp_id)
    else:
        d_dict = np.load(filename)
        stimulus = d_dict['stimulus']
        U = d_dict['U']
    return U.shape


def download_all(folder='allen_data'):
    csv_file = folder + '.csv'
    if not os.path.isfile(csv_file):
        experiments = boc.get_ophys_experiments(
            stimuli=[stim_info.NATURAL_SCENES],
            cre_lines=['Cux2-CreERT2', 'Emx1-IRES-Cre', 'Slc17a7-IRES2-Cre'])
        exp_df = pd.DataFrame(experiments)
        exp_df.to_csv(csv_file)
    else:
        exp_df = pd.read_csv(csv_file)
    order = np.random.permutation(len(exp_df))
    exp_df['n_stim'] = np.nan
    exp_df['n_cell'] = np.nan
    for idx in order:
        n_stim, n_cell = download(exp_df['id'][idx], folder=folder)
        print('downloaded %d: %d' % (idx, exp_df['id'][idx]))
        exp_df.at[idx, 'n_stim'] = n_stim
        exp_df.at[idx, 'n_cell'] = n_cell
    if not os.path.isfile(csv_file):
        exp_df.to_csv(csv_file)


def resample(n_subj, n_stim, n_repeat, n_cell, folder='allen_data',
             targeted_structure='VISal'):
    """ gets a resampled dataset generated by sampling from the allen dataset

    Args:
    n_subj (int): number of mice
    n_stim (int): number of stimuli
    n_repeat (int): number of repeats
    n_cell (int): number of cells
    folder (str, folder), optional:
        the folder with the downloaded data. The default is 'allen_data'.

    targeted structures are:
        'VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISrl'

    Returns
    -------
    list of pyrsa.data.Dataset for the requested data, one dataset per subject

    """
    csv_file = folder + '.csv'
    exp_df = pd.read_csv(csv_file)
    exp_df = exp_df[exp_df.n_cell >= n_cell]
    right_tar_df = exp_df[exp_df['targeted_structure'] == targeted_structure]
    subs = np.unique(right_tar_df['donor_name'])
    subj_idx = subs[np.random.permutation(len(subs))[:n_subj]]
    stim_idx = np.random.permutation(118)[:n_stim]
    U_all = np.empty((n_subj, n_stim, n_repeat, n_cell))
    for i_subj, subj in enumerate(subj_idx):
        right_sub_df = right_tar_df[
            right_tar_df['donor_name'] == subj]
        if len(right_sub_df) == 1:
            exp_id = right_sub_df.iloc()[0]['id']
        else:
            k = np.random.randint(len(right_sub_df))
            exp_id = right_sub_df.iloc()[k]['id']
        dat = np.load('allen_data/U_%d.npz' % exp_id)
        U = dat['U']
        stimulus = dat['stimulus']
        for i_stim, stim in enumerate(stim_idx):
            U_stim = U[stimulus == stim]
            rep_idx = np.random.permutation(U_stim.shape[0])[:n_repeat]
            cell_idx = np.random.permutation(U_stim.shape[1])[:n_cell]
            U_all[i_subj, i_stim] = U_stim[rep_idx][:, cell_idx]
    U_pyrsa = U_all.transpose(0, 3, 1, 2).reshape(
        n_subj, n_cell, n_stim * n_repeat).transpose(0, 2, 1)
    stim = np.repeat(stim_idx, n_repeat)
    datasets = []
    for i_subj in range(n_subj):
        v = np.var(U_pyrsa[i_subj], 0)  # variance to exclude constant cells
        dataset = pyrsa.data.Dataset(
            U_pyrsa[i_subj, :, v > 0],
            obs_descriptors={
                'stim': stim},
            descriptors={
                'subj': i_subj,
                'n_repeat': n_repeat,
                'n_stim': n_stim,
                'n_cell': n_cell,
                'targeted_structure': targeted_structure}
            )
        datasets.append(dataset)
    return datasets


def get_model_rdm(folder='allen_data', method='crossnobis', sim_type='cosine',
                  targeted_structure='VISal', min_cell=20):
    file_name = os.path.join(folder, method, sim_type)
    os.makedirs(file_name, exist_ok=True)
    file_name = os.path.join(
        file_name, targeted_structure + '_' + str(min_cell) + '.hdf5')
    if os.path.exists(file_name):
        rdm = pyrsa.rdm.load_rdm(file_name)
    else:
        csv_file = folder + '.csv'
        exp_df = pd.read_csv(csv_file)
        exp_df = exp_df[exp_df.n_cell >= min_cell]
        right_tar_df = exp_df[exp_df['targeted_structure'] == targeted_structure]
        subs = np.unique(right_tar_df['donor_name'])
        datasets = []
        for i_subj, subj in enumerate(subs):
            right_sub_df = right_tar_df[
                right_tar_df['donor_name'] == subj]
            for i_exp, exp_row in right_sub_df.iterrows():
                exp_id = exp_row['id']
                dat = np.load('allen_data/U_%d.npz' % exp_id)
                U = dat['U']
                stimulus = dat['stimulus']
                dataset = pyrsa.data.Dataset(
                    U,
                    obs_descriptors={
                        'stim': stimulus},
                    descriptors={
                        'subj': i_subj,
                        'targeted_structure': targeted_structure}
                    )
                datasets.append(dataset)
        # we don't have a cv_descriptor here
        rdms = pyrsa.rdm.calc_rdm(datasets, method=method, descriptor='stim',
                                  cv_descriptor=None)
        rdm = pyrsa.util.inference_util.pool_rdm(rdms, method=sim_type)
        rdm.save(file_name)
    return rdm


def get_models(folder='allen_data', method='crossnobis', sim_type='cosine',
               min_cell=20):
    target_structures = ['VISl', 'VISpm', 'VISrl', 'VISp', 'VISam', 'VISal']
    models = []
    for target in target_structures:
        rdm = get_model_rdm(
            folder=folder, method=method, sim_type=sim_type,
            targeted_structure=target, min_cell=min_cell)
        models.append(pyrsa.model.ModelFixed(target, rdm))
    return models


def sim_allen(
        idx, allen_folder='allen_data',
        n_cell=20, n_subj=10, n_stim=40, n_repeat=20,
        simulation_folder='sim_allen', n_sim=100,
        rdm_comparison='cosine', rdm_type='crossnobis',
        noise_type='eye', boot_type='both',
        start_idx=0):
    """ resamples the allen data and runs the RSA analysis on each sample
    always resamples subjects, cells, stimuli and repeats
    """
    fname_base = os.path.join(simulation_folder, str(idx))
    if not os.path.isdir(fname_base):
        os.makedirs(fname_base)
    res_name = os.path.join(fname_base, 'res_%03d.hdf5')
    models = get_models(folder=allen_folder, method=rdm_type,
                        sim_type=rdm_comparison, min_cell=n_cell)
    for i in tqdm.trange(start_idx, n_sim, position=1):
        data = resample(n_subj, n_stim, n_repeat, n_cell)
        # calculate RDMs
        if noise_type == 'eye':
            noise = None
        else:
            noise = []
            for dataset in data:
                noise.append(pyrsa.data.noise.prec_from_measurements(
                    dataset, 'stim', method=noise_type))
        rdms = pyrsa.rdm.calc_rdm(data, method=rdm_type, descriptor='stim',
                                  cv_descriptor=None, noise=noise)
        # run analysis
        results = run_inference(models, rdms, method=rdm_comparison,
                                bootstrap=boot_type)
        results.save(res_name % (i))


def run_allen(file_name='allen_tasks.csv', simulation_folder='sim_allen',
              allen_folder='allen_data', n_sim=100):
    task_df = pd.read_csv(file_name, index_col=0)
    order = np.random.permutation(np.arange(len(task_df)))
    for i_task in tqdm.tqdm(order, position=0):
        row = task_df.iloc()[i_task]
        fname_base = os.path.join(simulation_folder, str(row.name))
        start_idx = 0
        while os.path.isfile(os.path.join(fname_base, 'res_%03d.hdf5' % start_idx)):
            start_idx += 1
        if start_idx < n_sim:
            sim_allen(
                row.name, allen_folder=allen_folder,
                n_cell=row.n_cell, n_subj=row.n_subj, n_stim=row.n_stim,
                n_repeat=row.n_repeat,
                simulation_folder=simulation_folder, n_sim=n_sim,
                rdm_comparison=row.rdm_comparison, rdm_type='crossnobis',
                noise_type=row.noise_type, boot_type='both',
                start_idx=start_idx)
        task_df.at[i_task, 'finished'] = 1
        task_df.to_csv(file_name)


def save_task_list(file_name='allen_tasks.csv'):
    n_cell = [10, 20, 40]
    n_subj = [5, 10, 20]
    n_stim = [10, 20, 40]
    n_repeat = [5, 10, 20, 40]
    noise_type = ['eye', 'diag', 'shrink_diag', 'shrink_eye']
    rdm_comparison = ['cosine', 'corr', 'corr_cov', 'cosine_cov']
    grid = np.meshgrid(n_cell, n_subj, n_stim, n_repeat, noise_type, rdm_comparison, [0])
    table = [i.flatten() for i in grid]
    df = pd.DataFrame(table).transpose()
    df.columns = ['n_cell', 'n_subj', 'n_stim', 'n_repeat', 'noise_type',
                  'rdm_comparison', 'finished']
    df.to_csv(file_name)


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('-f', '--folder', type=str,
                        help='where should the allen data be?',
                        default='allen_data')
    parser.add_argument('action', help='what to do?', type=str,
                        choices=['download', 'save_list', 'run', 'nothing'],
                        default='nothing', nargs='?')
    args = parser.parse_args()
    if args.action == 'download':
        download_all(args.folder)
    elif args.action == 'save_list':
        save_task_list()
    elif args.action == 'run':
        run_allen(allen_folder=args.folder)
    else:
        print('No action selected, I am done!')
