{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating dissimilarities\n",
    "\n",
    "This tutorial shows how to estimate Representational Dissimilarity Matricies (RDMs) from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant imports\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrsa\n",
    "import pyrsa.data as rsd # abbreviation to deal with dataset\n",
    "import pyrsa.rdm as rsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate an example dataset we want to calculate RDM(s) from. If you are unfamiliar with the dataset object in pyrsa, have a look at `example_dataset.ipynb`. \n",
    "\n",
    "For this tutorial we use simulated data for the 92 image dataset, which come with the toolbox and are here just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset object\n",
    "measurements = io.matlab.loadmat('92imageData/simTruePatterns.mat')\n",
    "measurements = measurements['simTruePatterns2']\n",
    "nCond = measurements.shape[0]\n",
    "nVox = measurements.shape[1]\n",
    "# now create a  dataset object\n",
    "des = {'session': 1, 'subj': 1}\n",
    "obs_des = {'conds': np.array(['cond_%02d' % x for x in np.arange(nCond)])}\n",
    "chn_des = {'voxels': np.array(['voxel_' + str(x) for x in np.arange(nVox)])}\n",
    "data = rsd.Dataset(measurements=measurements,\n",
    "                   descriptors=des,\n",
    "                   obs_descriptors=obs_des,\n",
    "                   channel_descriptors=chn_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating our first RDM\n",
    "The main function to calculate RDMs from data is `pyrsa.rdm.calc_rdm` which we have abbreviated access as `rsr.calc_rdm` here. The function takes a dataset object as its main input. Additionally, we here pass the descriptor 'conds' to specify that we want to create a RDM of dissimilarities between conditions as specified by 'conds'. If this input is not provided the RDM is calculated assuming that each row is a separate pattern or condition. To avoid confusion, we generally recommend to pass the `descriptor` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a RDM\n",
    "RDM_euc = rsr.calc_rdm(data, descriptor='conds')\n",
    "print(RDM_euc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see the RDMs object can be printed for easy inspection.\n",
    "The calculated dissimilarities are saved as a vector of strung-out upper-triangular elements of the RDM matrix. Note also that the RDM object inherits the descriptors from the dataset object.\n",
    "\n",
    "By default `calc_rdm` computes squared euclidean distances between mean patterns. If we want to compute a different type of RDM, we can do so by passing the `method` parameter. See https://rsa3.readthedocs.io/en/latest/distances.html for a discussion of different methods for calculating RDMs.\n",
    "For example we can calculate correlation distances like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDM_corr = rsr.calc_rdm(data, method='correlation', descriptor='conds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the dissimilarities saved in the rdms object use the `get_matrices` and `get_vectors` functions. These functions always have a starting dimension for multiple rdms as the rdms object can store multiple rdms as we discuss below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_vectors = RDM_euc.get_vectors() # here a vector\n",
    "dist_matrix = RDM_euc.get_matrices()\n",
    "print(dist_matrix)\n",
    "print(dist_matrix.shape)\n",
    "print(dist_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, for a quick look we can plot the RDM using `pyrsa.vis.show_rdm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrsa.vis.show_rdm(RDM_euc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already calculated a RDM in some different way you can turn your RDM into a RDM object for use in pyrsa by using the constructor `pyrsa.rdm.RDMs`. If you want to use descriptors for the conditions or rdms you put into the object you need to specify them as dictionaries of lists as for the dataset object.\n",
    "\n",
    "The following thus creates a naked RDMs object, which only contains the dissimilarities and no specific descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RDM object with given entries:\n",
    "dissimilarities = RDM_euc.get_vectors()\n",
    "RDM_euc_manual = rsr.RDMs(dissimilarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create RDM object for several RDMs\n",
    "When we have multiple datasets we can compute the RDMs for each by simply passing the whole list to the function. This is convenient when we want to compute RDMs for multiple subjects, conditions, brain areas, etc.\n",
    "\n",
    "To illustrate this let's start by creating a list of 5 datasets with noisy copies of the measurements we already have, labeling them as coming from different subjects in the descriptor `'subj'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for i in range(5):\n",
    "    m_noisy = measurements + np.random.randn(*measurements.shape)\n",
    "    des = {'session': 1, 'subj': i}\n",
    "    data_list.append(rsd.Dataset(measurements=m_noisy,\n",
    "                   descriptors=des,\n",
    "                   obs_descriptors=obs_des,\n",
    "                   channel_descriptors=chn_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As promised we can now calculate the RDMs for all subjects in one go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdms = rsr.calc_rdm(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that `rdms` is a single object, which contains all RDMs. The functions for accessing the vector representation and the matrix representation are still available. Additionally, the number of RDMs and the descriptiors we gave to the dataset objects are kept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of RDMs is:')\n",
    "print(rdms.n_rdm)\n",
    "print()\n",
    "print('The descriptors for the RDMs are:')\n",
    "print(rdms.rdm_descriptors)\n",
    "print()\n",
    "print('The patterns or conditions are still described at least by their label:')\n",
    "print(rdms.pattern_descriptors['pattern'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To access the parts of the rdms object a few functions are available:\n",
    "To access only a subset of the rdms in the object use the `subset` and `subsample` functions:\n",
    "The inputs to these functions are a descriptor used for the selection and a list (or other iterable) of selected values.\n",
    "\n",
    "The difference between the two function lies in how they treat repetitions. If you pass a value twice subsample will repeat the rdm in the returned object, while subset will return every rdm at most once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same output:\n",
    "r1 = rdms.subset('subj', [1, 3, 4])\n",
    "r2 = rdms.subsample('subj', [1, 3, 4])\n",
    "# different output\n",
    "r3 = rdms.subset('subj', [1, 3, 3, 4])\n",
    "r4 = rdms.subsample('subj', [1, 3, 3, 4])\n",
    "# r3 has 3 rdms r4 has 4 rdms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent syntax for selecting a subset of the patterns is implemented as `subset_pattern` and `subsample_pattern`.\n",
    "\n",
    "For repeated values subsample will fill in dissimilarities between patterns and themselves as `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same output:\n",
    "r1 = rdms.subset_pattern('pattern', [1, 3, 4, 5, 6, 72])\n",
    "r2 = rdms.subsample_pattern('pattern', [1, 3, 4, 5, 6, 72])\n",
    "# different output\n",
    "r3 = rdms.subset_pattern('pattern', [1, 3, 3, 4, 5, 6, 72])\n",
    "r4 = rdms.subsample_pattern('pattern', [1, 3, 3, 4, 5, 6, 72])\n",
    "# r3 has 6 conditions r4 has 7 conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing and iterating over RDMs is also supported, i.e. `rdms[0]` will return the first rdm and `for rdm in rdms:` are legal commands. These commands return copies though!, i.e. `rdms[0]` and `rdm` will be copies of the corresponding rdms and changing them will not affect the original rdms object.\n",
    "\n",
    "And of course we can still show the rdm in a plot using `pyrsa.vis.show_rdm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrsa.vis.show_rdm(rdms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossvalidated dissimilarities\n",
    "When we have multiple independent measurements of a pattern we can use crossvalidated distances to achieve an unbiased estimate of the dissimilarities between patterns. Essentially, this is meant to counteract the upward bias caused by adding noise to the measurements. You may have noticed this bias by comparing the noisy RDMs we just created and the clean rdm we created at the beginning of this tutorial.\n",
    "\n",
    "To illustrate how to do this using pyrsa, we first create a dataset with multiple (`n_rep`) measurements for each pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rep = 10\n",
    "m_noisy = np.repeat(measurements, n_rep, axis=0)\n",
    "m_noisy += np.random.randn(*m_noisy.shape)\n",
    "    \n",
    "conds = np.array(['cond_%02d' % x for x in np.arange(nCond)])\n",
    "sessions = np.tile(np.arange(n_rep), 92)\n",
    "conds = np.repeat(conds, n_rep)\n",
    "obs_des = {'conds': conds, 'sessions': sessions}\n",
    "\n",
    "des = {'subj': 1}\n",
    "\n",
    "dataset = rsd.Dataset(\n",
    "    measurements=m_noisy,\n",
    "    descriptors=des,\n",
    "    obs_descriptors=obs_des,\n",
    "    channel_descriptors=chn_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, we added a sessions descriptor which marks which measurement comes from which session. We can now compute the crossvalidated distances simply using the `'crossnobis'` rdm calculation method. To specify which measurements come from the same session we pass `'sessions'` as the `cv_descriptor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_cv = pyrsa.rdm.calc_rdm(dataset, method='crossnobis', descriptor='conds', cv_descriptor='sessions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrsa.vis.show_rdm(rdm_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this rdm, we can see that this indeed removed the overall upward bias, although the rdm is still noisy of course.\n",
    "\n",
    "If you have multiple datasets for multiple subjects this will still work fine with the crossnobis dissimilarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking the noise covariance into account\n",
    "It is possible to take into account the noise covariance to get a more reliable estimate of the RDM. For computational efficiency reasons all functions which compute these dissimilarities in this toolbox take the precision matrix as input.\n",
    "\n",
    "To do so, the first step is to estimate the noise precision matrix. There are multiple estimates implemented in pyrsa.\n",
    "\n",
    "\n",
    "### diagonal covariance from measurements\n",
    "The first one is computing the variances and using the diagonal precision matrix, which is equivalent to normalizing each channel separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the covariance is never used in pyrsa\n",
    "# noise_cov_diag = pyrsa.data.noise.cov_from_measurements(dataset, obs_desc='conds', method='diag')\n",
    "# computing the precision matrix (inverse of CoV) instead:\n",
    "noise_prec_diag = pyrsa.data.noise.prec_from_measurements(dataset, obs_desc='conds', method='diag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shrinkage estimate from measurements\n",
    "The second method for estimating the noise covariance are shrinkage estimates which mix a diagonal matrix with the sample covariance to achieve an invertible, more accurate estimate of the covariance.\n",
    "\n",
    "In pyrsa this is implemented in the same function, just changing the method parameter. There are two variants: `'shrinkage_eye'` implements a shrinkage towards a multiple of the diagonal, `'shrinkage_diag'` shrinks towards the data diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_prec_shrink = pyrsa.data.noise.prec_from_measurements(dataset, obs_desc='conds', method='shrinkage_eye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_prec_shrink = pyrsa.data.noise.prec_from_measurements(dataset, obs_desc='conds', method='shrinkage_diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(noise_prec_shrink), plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimates based on residuals\n",
    "A different source for the noise covariance can be measures from an earlier step in the analysis, which lead to the dataset object. Most of the times these measures would be the residuals of a 1st level analysis to estimate the activations caused by the conditions or stimuli.\n",
    "\n",
    "To use this source for the noise covariance simply put the measurements you wish to use into a $n_{res}\\times k$ matrix, where $k$ is the number of measurement channels and run the following commands from the noise handling in pyrsa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = np.random.randn(1000, dataset.n_channel) # obviously do not use random residuals for this in applications\n",
    "noise_pres_res = pyrsa.data.noise.prec_from_residuals(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyrsa.data.noise.prec_from_residuals` takes the same method argument as `prec_from_measurements` allowing for diagonal covariance and shrinkage estimates.\n",
    "\n",
    "Also there is a `dof` argument, which allows you to provide the degrees of freedoms left in the residuals to correct the estimate for components removed via regression. This only scales the matrix, which means that this can be ignored if the absolute scale of the RDM does not matter to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Mahalanobis distances\n",
    "Mahalanobis distances is the simplest form of dissimilarities to take the covariance between measurement channels into account. This is reweighting channels with the estimate of the precision matrix.\n",
    "\n",
    "In pyrsa this is implemented as the `'mahalanobis'` method parameter of `calc_rdm`. The noise precision is passed as the `noise` parameter. For comparison we here also compute the euclidean RDM on the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_euc = pyrsa.rdm.calc_rdm(dataset, descriptor='conds', method='euclidean')\n",
    "rdm_maha_diag = pyrsa.rdm.calc_rdm(dataset, descriptor='conds', method='mahalanobis', noise=noise_prec_diag)\n",
    "rdm_maha_shrink = pyrsa.rdm.calc_rdm(dataset, descriptor='conds', method='mahalanobis', noise=noise_prec_shrink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the three estimated rdms, we can plot them with the following code. In this case the differences are fairly small, as we added independent and equally sized noise to the measurements. When the measurement channels are correlated and/or differently noisy this will result in different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pyrsa.vis.colors.rdm_colormap()\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rdm_euc.get_matrices()[0], cmap=cm)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Euclidean')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(rdm_maha_diag.get_matrices()[0], cmap=cm)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Diagonal')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(rdm_maha_shrink.get_matrices()[0], cmap=cm)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Shrinkage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the noise covariance into account can be combined with crossvalidated dissimilarities by computing cross-nobis dissimilarities. This is implemented as the `crossnobis` method of calculating RDMs in pyrsa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_cv_diag = pyrsa.rdm.calc_rdm(dataset, descriptor='conds', method='crossnobis', noise=noise_prec_diag, cv_descriptor='sessions')\n",
    "rdm_cv_shrink = pyrsa.rdm.calc_rdm(dataset, descriptor='conds', method='crossnobis', noise=noise_prec_shrink, cv_descriptor='sessions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can of course plot these matricies again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pyrsa.vis.colors.rdm_colormap()\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rdm_euc.get_matrices()[0], cmap=cm)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Euclidean')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(rdm_cv_diag.get_matrices()[0], cmap=cm)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Diagonal')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(rdm_cv_shrink.get_matrices()[0], cmap=cm)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Shrinkage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
